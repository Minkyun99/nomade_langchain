{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs and Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are eight planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "# a = llm.predict(\"How many planets are there?\") // text-davinci-003 2024.01.04 out of service -> 실행 안 됨\n",
    "b = chat.predict(\"How many planets are there?\") # In service gpt-3.5-turbo\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! chat is not default parameter.\n",
      "                    chat was transferred to model_kwargs.\n",
      "                    Please confirm that chat is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1 # temperature가 높을수록 창의력이 떨어짐, 답변의 활용도가 낮음\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao! Il mio nome è Paolo. La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Ciao! Il mio nome è Paolo. La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a geography expert. And you only reply in Italian.\"),\n",
    "    AIMessage(content = \"Ciao, mi chiam Paolo!\"),\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand. Also, what is your name?\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FewShoutPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the capital of France'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: langchain modules study\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate # 질문을 받고 답변을 할 수 있는 PROMPT를 제작하는 모듈\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate # AI가 답변하는 형식을 학습시킬 수 있는 모듈 -> 대화 방식을 데이터 베이스에 저장하여 가지고 오면 편함\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "t = PromptTemplate(\n",
    "    template=\"what is the capital of {country}\",\n",
    "    input_variables=['country'],\n",
    ")\n",
    "\n",
    "t.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI\n",
      "    I know this:\n",
      "    Capital: Ankara\n",
      "    Language: Turkish\n",
      "    Food: Kebab and Baklava\n",
      "    Currency: Turkish Lira"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI\\n    I know this:\\n    Capital: Ankara\\n    Language: Turkish\\n    Food: Kebab and Baklava\\n    Currency: Turkish Lira')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "{\n",
    "    \"question\": \"what do you know about Italy?\",\n",
    "    \"answer\": \"\"\"\n",
    "    Here is what I know:\n",
    "    Capital : Rome\n",
    "    Language: Italian\n",
    "    Good: Pizza and Pasta\n",
    "    Currency: Euro\"\"\"\n",
    "},\n",
    "{\n",
    "    \"question\": \"what do you know about Greece?\",\n",
    "    \"answer\": \"\"\"\n",
    "    I know this:\n",
    "    Capital: Athens\n",
    "    Language: Greek\n",
    "    Good:Souvlaki and Feta Cheese\n",
    "    Currency: Euro\"\"\"\n",
    "},\n",
    "{\n",
    "    \"question\": \"what do you kow about France?\",\n",
    "    \"answer\": \"\"\"I know this:\n",
    "    Capital : Paris\n",
    "    Language: French\n",
    "    Food: Wine and Cheese\n",
    "    Currency: Euro\"\"\"\n",
    "}\n",
    "]\n",
    "# chat.predict(\"what do you know about France?\")\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI{answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples = examples,\n",
    "    suffix=\"Human: What do you know about{country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "                                              \n",
    "\n",
    "prompt.format(country=\"Germany\")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Turkey\"\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
